# Servers.
conductor.grpc-server.enabled=false

# Database persistence type.
conductor.db.type=dynomite

# Dynomite Cluster details.
# format is host:port:rack separated by semicolon
conductor.redis.hosts=redis://redis:raaX7ZPlxpHpSYPQbTiYA3U1MAhgXmIF@redis-19083.c1.ap-southeast-1-1.ec2.cloud.redislabs.com:19083

# Dynomite cluster name
conductor.redis.clusterName=dyno1

# Namespace for the keys stored in Dynomite/Redis
conductor.redis.workflowNamespacePrefix=conductor

# Namespace prefix for the dyno queues
conductor.redis.queueNamespacePrefix=conductor_queues

# No. of threads allocated to dyno-queues (optional)
queues.dynomite.threads=10

# By default with dynomite, we want the repairservice enabled
conductor.app.workflowRepairServiceEnabled=true

# Non-quorum port used to connect to local redis.  Used by dyno-queues.
# When using redis directly, set this to the same port as redis server
# For Dynomite, this is 22122 by default or the local redis-server port used by Dynomite.
conductor.redis.queuesNonQuorumPort=22122

# Transport address to elasticsearch
conductor.elasticsearch.url=http://elastic:8VykdRNGp0ZHFHfnKfX9gsWK@3022c9e5f87c45a4a0bdda435c9bbc16.us-east-1.aws.found.io:9243
conductor.indexing.enabled=true
conductor.elasticsearch.version=6

# Name of the elasticsearch cluster
conductor.elasticsearch.indexName=conductor

# Additional modules for metrics collection exposed via logger (optional)
# conductor.metrics-logger.enabled=true
# conductor.metrics-logger.reportPeriodSeconds=15

# Additional modules for metrics collection exposed to Prometheus (optional)
# conductor.metrics-prometheus.enabled=true

# To enable Workflow/Task Summary Input/Output JSON Serialization, use the following:
# conductor.app.summary-input-output-json-serialization.enabled=true

# Load sample kitchen sink workflow
loadSample=true
